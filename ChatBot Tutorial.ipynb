{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Fundamentals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interactive guide to writing bots in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://apps.worldwritable.com/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이거는 서비스를 사용화하기 위한 튜토리얼은 아니지만 (아마 서비스를 위해서는 기존의 봇 플랫폼이나 프래임워크를 사용해야할 것이다.) 이 예제를 통해 conversational UI를 디자인하고 엔지니어링해볼 좋은 기회이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The boundries of a bot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당신이 conversational UI를 만들기 위해서는 다음 기본적 디자인 질문에 답해야 한다.\n",
    "\n",
    "1. Domain knowledge: What does a user expect this bot to understand?\n",
    "\n",
    "2. Personality: What tone or vocabulary does the bot employ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain knowledge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순도 백퍼센트 AI는 존재하지 않지만, AI는 특정 사실에 기반한 답을 인간처럼 답할 수는 있다. 모든 봇들은 특정 주제에 한정되어 있다. \n",
    "\n",
    "Open domain vs Closed domain(대부분의 봇은 closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "봇은 이해력의 부족으로 인해 진짜 인간보다 조금 덜떨어진 의인화를 해왔다. 이는 창조적 기회가 될 수도 있다. 진짜 인간 같은 의인화를 할 수 없다면 어떠한 컨셉을 정하는 것?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often the dual axes of domain and personality align: in the program ELIZA, the domain was a therapy session, and the bot’s personality was that of a Rogerian therapist. Domain and personality don’t necessarily need to be tightly coupled, though—an ecommerce bot needs to know about products, sizing, and order status, but that domain doesn’t imply any particular kind of personality. A shopping bot could have the persona of a helpful person, a cheerful kitten, or have no personality at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet \"Brobot\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 기본적인 수준의 챗봇 테크닉을 소개한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인사를 했을 때 답해주길 바랄 것이다. \"greet the robot\" 기능을 구현하기 위해 simple keyword matching 테크닉을 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentences we'll respond with if the user greeted us\n",
    "GREETING_KEYWORDS = (\"ㅎㅇ\", \"하이\", \"안녕\", \"안뇽\", \"하잉\", \n",
    "                     \"하이여\",\"하이요\",\"하이하이\", \"안녕하세요\",)\n",
    "\n",
    "GREETING_RESPONSES = [\"ㅎㅇ\", \"하이~~\",\"안뇽하쇼~\"]\n",
    "\n",
    "def check_for_greeting(sentence):\n",
    "    \"\"\"If any of the words in the user's input was a greeting, \n",
    "    return a greeting response\"\"\"\n",
    "    words = re.sub(\"[^['가-힣']]\", \" \",  sentence).split()\n",
    "    for word in words:\n",
    "        if word.lower() in GREETING_KEYWORDS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[하이3, ㅋㅋㅋ]\n"
     ]
    }
   ],
   "source": [
    "pprint(re.sub(\"[^['가-힣']]\", \" \",  '하이3 ㅋㅋㅋ').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안뇽하쇼~\n"
     ]
    }
   ],
   "source": [
    "answer = check_for_greeting('하이 ㅋㅋ')\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 챗봇 내에서 가장 간단한 실행이다. 유저의 텍스트로부터 특정 단어가 포함되었는지를 체크하여 만약 있으면 저장해둔 답변으로부터 랜덤으로 뽑아서 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Beyond keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 NLP를 하려면 두 개의 high-level 라이브러리를 필요로한다. 바로 TextBlob과 spaCy이다.spaCy는 사용하기 쉽고 빠르지만 메모리 집약적이고 통계적 NLP 전체를 커버하지 못할 수도 있다.\n",
    "TextBlob은 NLTK의 wraping하는 api이다. 더 느리지만 이해력은 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 TextBlob을 사용할 것이다.\n",
    "\n",
    "Brobot의 메인 루프는 다음의 스텝을 따른다.\n",
    "\n",
    "1. user's text에 초기 전처리를 가한다.(unsafe한 input을 체크하기도)\n",
    "\n",
    "2. TextBlot을 사용하여 input을 파싱한다.\n",
    "\n",
    "3. 유저의 발언으로부터 정보를 추출해내기 위한 루틴을 거친다.\n",
    "\n",
    "4. 유저의 발언과 가장 매칭이 되는 답변을 구성한다.\n",
    "\n",
    "5. 봇이 완전 x소리할 수도 있으니 후처리를 가한다. (최악의 경우는 면하기 위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    result = ''\n",
    "    for word in words:\n",
    "        result+=word\n",
    "        result+=' '\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = '하이 안녕하십니꺼~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하이 안녕하십니꺼'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = preprocess_text(sample)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed = TextBlob(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('하이', 'NN'), ('안녕하십니꺼', 'NN')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def respond(sentence):\n",
    "    \"\"\"Parse the user's inbound sentence and \n",
    "    find candidate terms that make up a best-fit response\"\"\"\n",
    "    cleaned = preprocess_text(sentence)\n",
    "    parsed = TextBlob(cleaned)\n",
    "\n",
    "    # Loop through all the sentences, if more than one. \n",
    "    #This will help extract the most relevant\n",
    "    # response text even across multiple sentences (for example if there was no obvious direct noun\n",
    "    # in one sentence\n",
    "    pronoun, noun, adjective, verb = find_candidate_parts_of_speech(parsed)\n",
    "\n",
    "    # If we said something about the bot and used some kind of direct noun, construct the\n",
    "    # sentence around that, discarding the other candidates\n",
    "    resp = check_for_comment_about_bot(pronoun, noun, adjective)\n",
    "\n",
    "    # If we just greeted the bot, we'll use a return greeting\n",
    "    if not resp:\n",
    "        resp = check_for_greeting(parsed)\n",
    "\n",
    "    if not resp:\n",
    "        # If we didn't override the final sentence, try to construct a new one:\n",
    "        if not pronoun:\n",
    "            resp = random.choice(NONE_RESPONSES)\n",
    "        elif pronoun == 'I' and not verb:\n",
    "            resp = random.choice(COMMENTS_ABOUT_SELF)\n",
    "        else:\n",
    "            resp = construct_response(pronoun, noun, verb)\n",
    "\n",
    "    # If we got through all that with nothing, use a random response\n",
    "    if not resp:\n",
    "        resp = random.choice(NONE_RESPONSES)\n",
    "\n",
    "    logger.info(\"Returning phrase '%s'\", resp)\n",
    "    # Check that we're not going to say anything obviously offensive\n",
    "    filter_response(resp)\n",
    "\n",
    "    return resp\n",
    "\n",
    "def find_candidate_parts_of_speech(parsed):\n",
    "    \"\"\"Given a parsed input, find the best pronoun, direct noun, adjective, and verb to match their input.\n",
    "    Returns a tuple of pronoun, noun, adjective, verb any of which may be None if there was no good match\"\"\"\n",
    "    pronoun = None\n",
    "    noun = None\n",
    "    adjective = None\n",
    "    verb = None\n",
    "    for sent in parsed.sentences:\n",
    "        pronoun = find_pronoun(sent)\n",
    "        noun = find_noun(sent)\n",
    "        adjective = find_adjective(sent)\n",
    "        verb = find_verb(sent)\n",
    "    logger.info(\"Pronoun=%s, noun=%s, adjective=%s, verb=%s\", pronoun, noun, adjective, verb)\n",
    "    return pronoun, noun, adjective, verb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 find_* 함수는 TextBlob의 sentence.pos_tags 속성에 따라 speech 중 단어의 파트를 리턴한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pronoun(sent):\n",
    "    \"\"\"Given a sentence, find a preferred pronoun to respond with. Returns None if no candidate\n",
    "    pronoun is found in the input\"\"\"\n",
    "    pronoun = None\n",
    "\n",
    "    for word, part_of_speech in sent.pos_tags:\n",
    "        # Disambiguate pronouns\n",
    "        if part_of_speech == 'PRP' and word.lower() == 'you':\n",
    "            pronoun = 'I'\n",
    "        elif part_of_speech == 'PRP' and word == 'I':\n",
    "            # If the user mentioned themselves, then they will definitely be the pronoun\n",
    "            pronoun = 'You'\n",
    "    return pronoun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대명사를 찾아주는 함수의 예\n",
    "유저가 'You'라고 하면 Brobot 입장에서는 'I'가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated approach would be to build a dependency tree. Dependency grammars describe the relationship among all clauses in a sentence, allowing you to discriminate between (say) the subject and object of a sentence. If your bot needs to know the difference between “dog bites man” and “man bites dog”, I recommend using the dependency parsing function of a library like spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But enough about me, what do you think of me?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 봇은 말하는 그 자체를 좋아한다. 이 특별한 루틴은 만약 유저가 bot에게 \"you\"라고 직접적 언급을 한 경우, 잠재적 답변을 만들어 낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_for_comment_about_bot(pronoun, noun, adjective):\n",
    "    \"\"\"Check if the user's input was about the bot itself, in which case try to fashion a response\n",
    "    that feels right based on their input. Returns the new best sentence, or None.\"\"\"\n",
    "    resp = None\n",
    "    if pronoun == 'I' and (noun or adjective):\n",
    "        if noun:\n",
    "            if random.choice((True, False)):\n",
    "                resp = random.choice(SELF_VERBS_WITH_NOUN_CAPS_PLURAL).format(**{'noun': noun.pluralize().capitalize()})\n",
    "            else:\n",
    "                resp = random.choice(SELF_VERBS_WITH_NOUN_LOWER).format(**{'noun': noun})\n",
    "        else:\n",
    "            resp = random.choice(SELF_VERBS_WITH_ADJECTIVE).format(**{'adjective': adjective})\n",
    "    return resp\n",
    "\n",
    "# Template for responses that include a direct noun which is indefinite/uncountable\n",
    "SELF_VERBS_WITH_NOUN_CAPS_PLURAL = [\n",
    "    \"My last startup totally crushed the {noun} vertical\",\n",
    "    \"Were you aware I was a serial entrepreneur in the {noun} sector?\",\n",
    "    \"My startup is Uber for {noun}\",\n",
    "    \"I really consider myself an expert on {noun}\",\n",
    "]\n",
    "\n",
    "SELF_VERBS_WITH_NOUN_LOWER = [\n",
    "    \"Yeah but I know a lot about {noun}\",\n",
    "    \"My bros always ask me about {noun}\",\n",
    "]\n",
    "\n",
    "SELF_VERBS_WITH_ADJECTIVE = [\n",
    "    \"I'm personally building the {adjective} Economy\",\n",
    "    \"I consider myself to be a {adjective}preneur\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 봇에서는 당신은 좀 더 정교한 <a href=\"http://jinja.pocoo.org/\">templating engine</a>이 필요할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a realistic response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 경우 유저의 텍스트로부터 파싱하여 단어를 알아낼 수 있지만 미처 처리하지 못한 단어들이 등장할 수도 있다. \n",
    "이 경우 프로그램은 이해하지 못한셈이다. 도메인 지식 밖의 일이라 예외를 만난 것이다.\n",
    "\n",
    "하지만 여전히 당신은 성공적인 답변을 생성해내기 위해 유저의 인풋을 수정할 수 있다. 하지만 이는 이해해서 답했다기 보다는 로봇의 성격을 드러내는 것에 더 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 만약 유저의 인풋으로부터 대명사를 받는다면 재활용한다.\n",
    "\n",
    "2. 많은 경우, 유저의 동사를 안바꾸고 사용한다.\n",
    "\n",
    "3. 만약 동사가 \"to be\"의 형태라면 이는 유저가 자기 자신에 대해 말하고 있는 것이다. (I am a good programmer), 이에 반대할 수도 있다?\n",
    "\n",
    "4. 그렇지 않다면 그냥 유저의 오리지널 문장을 재조합하고 미사여구를 더한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_response(pronoun, noun, verb):\n",
    "    \"\"\"No special cases matched, so we're going to try to construct a full sentence that uses as much\n",
    "    of the user's input as possible\"\"\"\n",
    "    resp = []\n",
    "\n",
    "    if pronoun:\n",
    "        resp.append(pronoun)\n",
    "\n",
    "    # We always respond in the present tense, and the pronoun will always either be a passthrough\n",
    "    # from the user, or 'you' or 'I', in which case we might need to change the tense for some\n",
    "    # irregular verbs.\n",
    "    if verb:\n",
    "        verb_word = verb[0]\n",
    "        if verb_word in ('be', 'am', 'is', \"'m\"):  # This would be an excellent place to use lemmas!\n",
    "            if pronoun.lower() == 'you':\n",
    "                # The bot will always tell the person they aren't whatever they said they were\n",
    "                resp.append(\"aren't really\")\n",
    "            else:\n",
    "                resp.append(verb_word)\n",
    "    if noun:\n",
    "        pronoun = \"an\" if starts_with_vowel(noun) else \"a\"\n",
    "        resp.append(pronoun + \" \" + noun)\n",
    "\n",
    "    resp.append(random.choice((\"tho\", \"bro\", \"lol\", \"bruh\", \"smh\", \"\")))\n",
    "\n",
    "    return \" \".join(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You've got to be kind "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 루틴은 unsafe한 output을 방지하기 위한 필터로써 동작한다. 공격적 언어나 등을 필터링한다. 또한 문맥적으로 적절하지 않은 답변도 필터링한다. \n",
    "\n",
    "배드 봇을 방지하는 것은 이론적으로 불가능하지만 봇 크리에이터들은 최대한 윤리적 의무를 지키려 노력한다..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_response(resp):\n",
    "    \"\"\"Don't allow any words to match our filter list\"\"\"\n",
    "    tokenized = resp.split(' ')\n",
    "    for word in tokenized:\n",
    "        if '@' in word or '#' in word or '!' in word:\n",
    "            raise UnacceptableUtteranceException()\n",
    "        for s in FILTER_WORDS:\n",
    "            if word.lower().startswith(s):\n",
    "                raise UnacceptableUtteranceException()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 Brobot의 여러 기능을 다뤘다. 하지만 전체 완성된 소스 코드들을 확인하길 바란다. https://github.com/lizadaly/brobot/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
