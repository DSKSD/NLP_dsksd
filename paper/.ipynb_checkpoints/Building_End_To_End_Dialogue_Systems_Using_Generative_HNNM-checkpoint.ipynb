{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원문 : https://arxiv.org/abs/1507.04808 <br>\n",
    "<br>\n",
    "작성자 : 김성동\n",
    "<br>\n",
    "개인적 이해를 돕고자 정리.. 궁금한 포인트? => __문맥합치기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import unicode_literals\n",
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 생성 모델을 이용한 large dialogue corpora에 기반한 오픈 도메인 대화 시스템을 만들기 위해 연구를 진행했다. 생성 모델은 현실적이고 유연한 상호작용을 위해 자동적으로 생성되는 word-by-word 답변을 제공한다. (* 좀 더 인간과 대화하는 느낌을 줄 수 있도록) <br>\n",
    "이러한 목적을 가지고, 우리는 최근에 제안된 __hierarchical recurrent encoder-decoder neural network__를 다이얼로그 도메인으로 확장하려 한다. 또한 이러한 모델이 기존의 n-gram model에 비해 얼마나 경쟁력 있는지 설명하겠다. 우리는 미리 훈련된 워드 임베딩 모델과 트레이닝 코퍼스보다 더 큰 코퍼스로(엄밀한 대화 데이터는 아니지만 주제의 연관이 있는 코퍼스) pretraining을 시킴으로 성능을 높일 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다이얼로그 시스템(Interactive conversational agents, virtual agents, chatterbots)은 크게 두 가지로 나눌 수 있다.\n",
    "1. goal-driven systems (특정한 목적을 가지고 있음. closed domain) ex. 기술 지원 서비스\n",
    "2. non-goal-driven systems (특정한 목정이 없음. open domain) ex. 언어학습도구 혹은 컴퓨터 게임 캐릭터 <br>\n",
    "<br>\n",
    "우리는 __non-goal-driven systems__에 집중하려 한다. 우리는 이러한 타입을 위한 큰 코퍼스를 이용할 수 있고 non-goal-driven systems은 goal-driven systems으로 일반화하기 쉽다. <br>\n",
    "아마 다이얼로그 시스템을 goal-driven systems으로 접근하는 가장 성공적인 방법은 다이얼로그 시스템을 __partially observable Markov decision process(POMDP)__로 보는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue system as POMDP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 설명 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상용시스템들 = 비싸고 시간이 많이 든다..! 좁은 도메인에만 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직까지 사용 시스템들은 state와 action space를 나타내기 위해 수작업으로 특징을 정의한다. 또한 아주 큰 task-specific corpus (특정 목적을 위한 코퍼스)가 필요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최근의 연구 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal-driven systems을 POMDP의 제약을 이용하여 아주 적은 예(데이터)로도 배울 수 있도록 연구하고 있다.(특징을 인공신경망 모델을 이용하여 학습하도록) 하지만 아직까지 이러한 시도들 역시 수작업(hand-crafted feafure)과 __task-specific simulated conversations__로 이루어진 큰 Corpora가 필요하다. <br>\n",
    "<br>\n",
    "* 특정 도메인에서 동작하도록 하기 위해 의도적인 대화 시뮬레이션 데이터를 수집하는듯?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-goal-driven systems을 만들게 된 동기들 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 명시적이거나 측정 가능한 목적이 딱히 없는 시스템(즉, Open domain의 다이얼로그 시스템)\n",
    "2. 만약 시스템이 goal-driven dialogue system의 테스크에 관련된 corpora로 훈련됐다면, 그러한 모델들은 앞서 말한 POMDP 모델들을 훈련시킬 수 있는 USER SIMULATOR로 사용할 수 있다.(유저 대신 연습 상대?) 이를 통해 가격을 낮추고 시간 낭비를 줄일 수도 있음.\n",
    "3. 또한 Non-goal-driven systems들은 POMDP 모델의 state space를 확장하는데 이용될 수도 있다. 이는 일반화를 도와준다.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model as a cognitive system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "natural lanuage understanding, reasoning, decision making, and natural language generation in order to replicate or emulate the behavior of the agents in the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 연구들과의 차이 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learning dialogue systems through interaction with humans(Young et al. 2013; Gasic et al. 2013; Cantrell et al. 2012; Mohan and Laird 2014) : off-line으로 corpus를 모사하는데 집중\n",
    "<br>\n",
    "* Our model : task-specific objective function 최대화 (선정의된 state와 action space가 필요없다. (즉, 룰이 필요 없다.?)) __inference mechanisms__을 통해 발언을 곧장 states로 매핑하고, __action generation mechanisms__을 통해 states를 acts로 매핑하고 확률적으로 답변을 만들어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 설명 사진 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기대효과 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노가다로 룰을 정의할 노력을 줄인다. (비용과 시간 감축) <br>\n",
    "게다가 우리는 대화가 길어져도 state를 유지할 수 있도록 효과적으로 훈련하는데 집중함. <br>\n",
    "* 대화가 길어져도 맥락을 가지고 대화할 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hierarchical recurrent encoder-decoder(HRED) (Sordoni et al. 2015a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 HRED를 다이얼로그 시스템의 테스크로 확장했다. * 기존의 HRED는 연쇄적인 질의 자동 생성에 사용됌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Related Work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modeling converstions on micro-blogging websites with generative probabilistic models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dialogue as a sequence of M utterances "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D = \\{U_1,...,U_M\\} $$ <br>\n",
    "$$ U_m = \\{w_{m,1},...,w_{m,N_m}\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다이얼로그(대화)는 M개의 발언 집합이고 하나의 발언은 N개의 토큰의 집합이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$P_\\theta(U_1,...,U_M) = \\prod_{m=1}^M P_\\theta(U_m|U_{<m}),$$\n",
    "$$ = \\prod_{m=1}^M \\prod_{n=1}^{N_m} P_\\theta(w_{m,n}|w_{m,<n},U_{<m}),  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 세타는 대화의 임의 길이에 영향을 준다. 이 세타에 영향을 받는 분포 P <br>\n",
    "m 이전의 발언들이 주어졌을 때 발언 m을 할 확률 <br>\n",
    "즉, 좀 더 나눠보면 m 이전의 발언들이 주어지고, m번째 발언의 n번째 토큰이 나오기 전 확률이 주어졌을 때, m번째 발언의 n번째 토큰의 확률\n",
    "<hr>\n",
    "이는 일반적인 language model과 비슷하지만 중요한 차이점은 <i>speech acts</i> 역시 token으로 사용되었다는 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding + RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 모델을 계산하여 모두 테이블로 만드는 것은 __차원의 저주__의 문제가 발생하기 때문에 이를 극복하기 위해 벤지오 교수가 제안했던 __word embeddings__ 방법을 사용한다. 또한 __RNN__을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
