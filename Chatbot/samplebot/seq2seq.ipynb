{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 파라미터와 API 정리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "               source_vocab_size,\n",
    "               target_vocab_size,\n",
    "               buckets,\n",
    "               size,\n",
    "               num_layers,\n",
    "               max_gradient_norm,\n",
    "               batch_size,\n",
    "               learning_rate,\n",
    "               learning_rate_decay_factor,\n",
    "               use_lstm=False,\n",
    "               num_samples=512,\n",
    "               forward_only=False,\n",
    "               dtype=tf.float32):\n",
    "        # buckets = [(5,10), (10,15), (20,25), (40,50)]\n",
    "        \n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.buckets = buckets\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = tf.Variable(\n",
    "            float(learning_rate), trainable=False, dtype=dtype)\n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "            self.learning_rate * learning_rate_decay_factor)\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        # sampled softmax를 사용하려면 output_projection이 필요하다\n",
    "        output_projection = None\n",
    "        softmax_loss_function = None\n",
    "        # Sampled softmax only makes sense if we sample less than vocabulary size.\n",
    "        # 샘플의 갯수가 target_vocab_size보다 작은 경우에만 사용한다.\n",
    "        # 더 큰 경우에는 표준 소프트맥스 손실함수가 낫다.\n",
    "        \n",
    "        if num_samples > 0 and num_samples < self.target_vocab_size:\n",
    "            w_t = tf.get_variable(\"proj_w\", [self.target_vocab_size, size], dtype=dtype)\n",
    "            w = tf.transpose(w_t)\n",
    "            b = tf.get_variable(\"proj_b\", [self.target_vocab_size], dtype=dtype)\n",
    "            output_projection = (w, b)\n",
    "            \n",
    "            def sampled_loss(inputs, labels):\n",
    "                labels = tf.reshape(labels, [-1, 1])\n",
    "                # We need to compute the sampled_softmax_loss using 32bit floats to\n",
    "                # avoid numerical instabilities.\n",
    "                local_w_t = tf.cast(w_t, tf.float32)\n",
    "                local_b = tf.cast(b, tf.float32)\n",
    "                local_inputs = tf.cast(inputs, tf.float32)\n",
    "                \n",
    "                return tf.cast(\n",
    "                        tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,\n",
    "                                                   num_samples, self.target_vocab_size),dtype)\n",
    "            \n",
    "            softmax_loss_function = sampled_loss\n",
    "\n",
    "            \"\"\"\n",
    "            weight matrix와 bias vector의 쌍으로 이루어진 출력 투영을 구성한다.\n",
    "            이것이 사용되는 경우, rnn cell은 (batch size x target_vocab_size)\n",
    "            대신 (batch size x size) 형태의 벡터를 반환한다.\n",
    "            로짓을 복원하려면 가중치 행렬로 곱한 뒤 편향 벡터를 더해야 한다. \n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "            # Create the internal multi-layer cell for our RNN.\n",
    "        single_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if use_lstm:\n",
    "            single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\n",
    "        cell = single_cell\n",
    "        if num_layers > 1:\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)\n",
    "\n",
    "        # The seq2seq function: we use embedding for the input and attention.\n",
    "        def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "              return tf.nn.seq2seq.embedding_attention_seq2seq(\n",
    "                  encoder_inputs,\n",
    "                  decoder_inputs,\n",
    "                  cell,\n",
    "                  num_encoder_symbols=source_vocab_size,\n",
    "                  num_decoder_symbols=target_vocab_size,\n",
    "                  embedding_size=size,\n",
    "                  output_projection=output_projection,\n",
    "                  feed_previous=do_decode,\n",
    "                  dtype=dtype)\n",
    "        \n",
    "        \"\"\"\n",
    "        encoder_inputs, decoder_inputs은 이산값을 나타내는 정수 벡터\n",
    "        이 입력은 밀도 높은 표현으로 임베드되는데 이 임베딩을 구성하기 위해\n",
    "        심볼들의 숫자들(num_encoder_symbols, num_decoder_symbols)을 지정할\n",
    "        필요가 있다.\n",
    "\n",
    "        * feed_previous : False이면 decoder_inputs 텐서를 그대로 사용,\n",
    "        True면 decoder_inputs의 첫 번째 원소만 사용한다? 리스트의 다른 텐서는\n",
    "        모두 무시되고, 인코더의 이전 결과를 대신 사용\n",
    "\n",
    "        * output_projection : 이 인자가 지정되지 않으면, 임베딩 모델의 출력은\n",
    "        생성된 각 심볼의 로짓을 나타내는 (batch size x num_decoder_symbols)\n",
    "        형태의 텐서로 나오게 되는데, 이렇게 되면 (num_decoder_symbols)가 클 때\n",
    "        실용적이지 않게 된다. \n",
    "\n",
    "        먼저 작은 출력 텐서를 반환하고 이후에 output_projection을 이용해서 큰 출력\n",
    "        텐서로 projection하는 편이 낫다. 이렇게 해서 sampled softmax loss와 함께\n",
    "        사용할 수 있다.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # bucket과 padding 사용\n",
    "\n",
    "        # Feeds for inputs.\n",
    "        self.encoder_inputs = []\n",
    "        self.decoder_inputs = []\n",
    "        self.target_weights = []\n",
    "        for i in range(buckets[-1][0]):  # Last bucket is the biggest one.\n",
    "            self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                    name=\"encoder{0}\".format(i)))\n",
    "        for i in range(buckets[-1][1] + 1):\n",
    "            self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],\n",
    "                                                    name=\"decoder{0}\".format(i)))\n",
    "            self.target_weights.append(tf.placeholder(dtype, shape=[None],\n",
    "                                                    name=\"weight{0}\".format(i)))\n",
    "\n",
    "        # Our targets are decoder inputs shifted by one.\n",
    "        targets = [self.decoder_inputs[i + 1]\n",
    "                   for i in range(len(self.decoder_inputs) - 1)]\n",
    "        \n",
    "             # Training outputs and losses.\n",
    "        if forward_only:\n",
    "            self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n",
    "              self.encoder_inputs, self.decoder_inputs, targets,\n",
    "              self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),\n",
    "              softmax_loss_function=softmax_loss_function)\n",
    "            # If we use output projection, we need to project outputs for decoding.\n",
    "            if output_projection is not None: # 여기서 로짓을 복원?\n",
    "                for b in range(len(buckets)):\n",
    "                    self.outputs[b] = [\n",
    "                    tf.matmul(output, output_projection[0]) + output_projection[1]\n",
    "                    for output in self.outputs[b]\n",
    "                    ]\n",
    "        else:\n",
    "            self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\n",
    "              self.encoder_inputs, self.decoder_inputs, targets,\n",
    "              self.target_weights, buckets,\n",
    "              lambda x, y: seq2seq_f(x, y, False),\n",
    "              softmax_loss_function=softmax_loss_function)\n",
    "\n",
    "        # Gradients and SGD update operation for training the model.\n",
    "        params = tf.trainable_variables()\n",
    "        if not forward_only:\n",
    "            self.gradient_norms = []\n",
    "            self.updates = []\n",
    "            opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "            for b in range(len(buckets)):\n",
    "                gradients = tf.gradients(self.losses[b], params)\n",
    "                clipped_gradients, norm = tf.clip_by_global_norm(gradients,\n",
    "                                                             max_gradient_norm)\n",
    "                self.gradient_norms.append(norm)\n",
    "                self.updates.append(opt.apply_gradients(\n",
    "                zip(clipped_gradients, params), global_step=self.global_step))\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 9 required positional arguments: 'source_vocab_size', 'target_vocab_size', 'buckets', 'size', 'num_layers', 'max_gradient_norm', 'batch_size', 'learning_rate', and 'learning_rate_decay_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d591aa447e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 9 required positional arguments: 'source_vocab_size', 'target_vocab_size', 'buckets', 'size', 'num_layers', 'max_gradient_norm', 'batch_size', 'learning_rate', and 'learning_rate_decay_factor'"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
